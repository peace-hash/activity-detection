{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 56, 68)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "TRAIN_PATH = '/kaggle/input/datafile/train'\n",
    "TEST_PATH = '/kaggle/input/datafile1/test'\n",
    "VAL_PATH = '/kaggle/input/datavalidation/val'\n",
    "\n",
    "train_datas = {}\n",
    "test_datas = {}\n",
    "val_datas = {}\n",
    "\n",
    "for dirname, _, filenames in os.walk(TRAIN_PATH):\n",
    "    for filename in filenames:\n",
    "        train_datas[filename] = os.path.join(dirname, filename)\n",
    "\n",
    "for dirname, _, filenames in os.walk(TEST_PATH):\n",
    "    for filename in filenames:\n",
    "        test_datas[filename] = os.path.join(dirname, filename)\n",
    "        \n",
    "for dirname, _, filenames in os.walk(VAL_PATH):\n",
    "    for filename in filenames:\n",
    "        val_datas[filename] = os.path.join(dirname, filename)\n",
    "\n",
    "        \n",
    "len(train_datas), len(test_datas), len(val_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "- 20Hz = 20 readings/seconds.\n",
    "- Activity Time = 3 minutes.\n",
    "- 180 * 20 = 3600 rows/eachactivity/eachsubject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "####################\n",
    "### Helper functions\n",
    "####################\n",
    "\n",
    "def window(width, overlap, max_idx):\n",
    "    \"\"\"\n",
    "    Generates tuples of indices that define a window\n",
    "    of given width and overlap. \n",
    "    \n",
    "    For example:\n",
    "    window(width=10, overlap=0.5, max_length=30)\n",
    "    (0, 10)\n",
    "    (5, 15)\n",
    "    (10, 20)\n",
    "    (15, 25)\n",
    "    Note: it trims the end; i.e. won't return (25, 30)\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    if overlap < 0.0 or overlap >= 1.:\n",
    "        raise ValueError(\"overlap needs to be a number between 0 and 1\")\n",
    "    while True:\n",
    "        end = start + width\n",
    "        if end >= max_idx:\n",
    "            return None\n",
    "        yield start, end\n",
    "        start += max(int((1-overlap)*width), 1)\n",
    "\n",
    "        \n",
    "def window_df(df, width, overlap):\n",
    "    \"\"\"\n",
    "    Applies window to a dataframe to return chunks of rows,\n",
    "    with overlap if specified.\n",
    "    \"\"\"\n",
    "    windows = window(width, overlap, len(df))\n",
    "    for start, end in windows:\n",
    "        yield df[start:end]\n",
    "\n",
    "\n",
    "def standardize(df):\n",
    "    \"\"\"\n",
    "    Make the mean of data 0 and normalize\n",
    "    \"\"\"\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "\n",
    "def zero_cross_rate(series):\n",
    "    \"\"\"\n",
    "    How often the signal changes sign (+/-)\n",
    "    \"\"\"\n",
    "    zero_cross_count = (np.diff(np.sign(series)) != 0).sum()\n",
    "    return zero_cross_count / len(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "SAMPLING_RATE = 20 # Data was recorded at 20Hz\n",
    "# Column names\n",
    "DATA_COLS = [\"x\", \"y\", \"z\"] # time series data\n",
    "TARGET_COL = [\"target\"] # the activity\n",
    "\n",
    "VALID_TARGETS = list(\"abcdefghijklmnopqrs\".upper())\n",
    "print(len(VALID_TARGETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "N_SECONDS = 2\n",
    "OVERLAP = 0.5\n",
    "\n",
    "def generate_features(df):\n",
    "    \n",
    "    # Ensure targets are valid values\n",
    "    master_valid = df[df['target'].isin(VALID_TARGETS)]\n",
    "\n",
    "    feature_matrix = []\n",
    "    # looping over groups helps make sure we don't\n",
    "    # consider windows with more than one target\n",
    "    for target, df in master_valid.groupby('target'):\n",
    "        \n",
    "        # 0-center the mean and normalize\n",
    "        df = standardize(df[DATA_COLS])\n",
    "                \n",
    "        grp = defaultdict(list)\n",
    "        grp['target'] = target\n",
    "        samples = window_df(df,\n",
    "                            width=N_SECONDS*SAMPLING_RATE, \n",
    "                            overlap=OVERLAP)\n",
    "        \n",
    "        for sample in samples:\n",
    "            means = sample[DATA_COLS].mean()\n",
    "            grp['x_mean'].append(means['x'])\n",
    "            grp['y_mean'].append(means['y'])\n",
    "            grp['z_mean'].append(means['z'])\n",
    "            \n",
    "            stds = sample[DATA_COLS].std()\n",
    "            grp['x_std'].append(stds['x'])\n",
    "            grp['y_std'].append(stds['y'])\n",
    "            grp['z_std'].append(stds['z'])\n",
    "            \n",
    "            grp['x_max_min'].append(max(sample[\"x\"]) - min(sample[\"x\"]))\n",
    "            grp['y_max_min'].append(max(sample[\"y\"]) - min(sample[\"y\"]))\n",
    "            grp['z_max_min'].append(max(sample[\"z\"]) - min(sample[\"z\"]))\n",
    "            \n",
    "            # correlations\n",
    "            corrs = sample[DATA_COLS].corr()\n",
    "            grp['xy_corr'].append(corrs.loc['x', 'y'])\n",
    "            grp['xz_corr'].append(corrs.loc['x', 'z'])\n",
    "            grp['yz_corr'].append(corrs.loc['y', 'z'])\n",
    "            \n",
    "            # root-mean-square(x, y, z)\n",
    "            rms = np.sqrt(np.mean(np.square(sample[DATA_COLS]), axis=1))\n",
    "            grp['rms_mean'].append(rms.mean())\n",
    "            grp['rms_std'].append(rms.std())\n",
    "\n",
    "            # zero crossing rate of amplitude (crossing below mean)\n",
    "            grp['x_zcr'].append(zero_cross_rate(sample['x']))\n",
    "            grp['y_zcr'].append(zero_cross_rate(sample['y']))\n",
    "            grp['z_zcr'].append(zero_cross_rate(sample['z']))\n",
    "\n",
    "            # amplitude kurtosis\n",
    "            kurtoses = kurtosis(sample[DATA_COLS])\n",
    "            grp['x_kurtosis'].append(kurtoses[0])\n",
    "            grp['y_kurtosis'].append(kurtoses[1])\n",
    "            grp['z_kurtosis'].append(kurtoses[2])\n",
    "\n",
    "            # fourier transforms!\n",
    "            x_fft = abs(np.fft.rfft(sample['x']))\n",
    "            y_fft = abs(np.fft.rfft(sample['y']))\n",
    "            z_fft = abs(np.fft.rfft(sample['z']))\n",
    "\n",
    "            grp['x_freq_max'].append(np.argmax(x_fft))\n",
    "            grp['y_freq_max'].append(np.argmax(y_fft))\n",
    "            grp['z_freq_max'].append(np.argmax(z_fft))\n",
    "\n",
    "            # Max Fourier \n",
    "            grp['x_fft_max'].append(x_fft.max())\n",
    "            grp['y_fft_max'].append(y_fft.max())\n",
    "            grp['z_fft_max'].append(z_fft.max())\n",
    "            \n",
    "            # Mean Fourier\n",
    "            grp['x_fft_mean'].append(x_fft.mean())\n",
    "            grp['y_fft_mean'].append(y_fft.mean())\n",
    "            grp['z_fft_mean'].append(z_fft.mean())\n",
    "\n",
    "            # Standard deviation Fourier\n",
    "            grp['x_fft_std'].append(x_fft.std())\n",
    "            grp['y_fft_std'].append(y_fft.std())\n",
    "            grp['z_fft_std'].append(z_fft.std())\n",
    "\n",
    "            grp['x_fft_kurtosis'].append(kurtosis(x_fft))\n",
    "            grp['y_fft_kurtosis'].append(kurtosis(y_fft))\n",
    "            grp['z_fft_kurtosis'].append(kurtosis(z_fft))\n",
    "\n",
    "        # Add grp to feature_matrix\n",
    "        feature_matrix.append(pd.DataFrame(grp))\n",
    "\n",
    "    # concatenate all groups into one dataframe\n",
    "    feature_matrix_df = pd.concat(feature_matrix)\n",
    "    \n",
    "    return feature_matrix_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_paths):\n",
    "    feature_dfs = []\n",
    "    for txt_file in data_paths:\n",
    "        txt_hints = txt_file.split('_')\n",
    "        print(\"Pre-Processing {} ...\".format(data_paths[txt_file]))\n",
    "        df = pd.read_csv(data_paths[txt_file], \n",
    "                     names = ['id', 'target', 'timestamp', 'x', 'y', 'z'])\n",
    "        df['z'] = df['z'].apply(lambda x: float(x.strip(';')))\n",
    "\n",
    "        fdf = generate_features(df)\n",
    "        fdf['idx'] = int(txt_hints[1])\n",
    "        fdf['sensor'] = txt_hints[2]\n",
    "        fdf['device'] = txt_hints[3].split('.')[0]\n",
    "        # print(idx_, sensor, device)\n",
    "        feature_dfs.append(fdf)\n",
    "    feature_df = pd.concat(feature_dfs)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing /kaggle/input/datafile/train/data_1600_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1613_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1616_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1605_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1600_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1607_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1615_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1602_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1613_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1602_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1607_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1617_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1608_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1605_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1602_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1611_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1614_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1619_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1605_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1606_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1611_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1617_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1611_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1610_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1600_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1617_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1603_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1601_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1616_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1609_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1618_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1604_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1609_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1606_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1607_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1614_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1614_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1602_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1600_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1610_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1613_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1601_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1610_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1607_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1601_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1609_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1612_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1612_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1616_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1610_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1603_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1608_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1615_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1606_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1612_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1618_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1617_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1604_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1604_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1619_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1618_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1606_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1612_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1603_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1618_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1601_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1614_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1608_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1611_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1608_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1616_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1613_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1609_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1619_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1615_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1605_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1604_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1619_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1603_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile/train/data_1615_accel_watch.txt ...\n"
     ]
    }
   ],
   "source": [
    "train_data = preprocess_data(train_datas)\n",
    "# save features\n",
    "output_file = \"train_data.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(train_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing /kaggle/input/datafile1/test/data_1624_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1622_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1631_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1624_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1622_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1624_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1621_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1630_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1633_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1632_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1620_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1620_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1621_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1625_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1623_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1629_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1629_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1631_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1627_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1630_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1623_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1623_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1631_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1626_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1625_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1621_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1627_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1623_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1625_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1632_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1627_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1626_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1627_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1633_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1621_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1626_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1631_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1620_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1629_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1630_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1633_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1629_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1625_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1626_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1628_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1630_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1632_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1628_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1622_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1624_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1628_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1628_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1620_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1633_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1632_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datafile1/test/data_1622_accel_phone.txt ...\n"
     ]
    }
   ],
   "source": [
    "test_data = preprocess_data(test_datas)\n",
    "# save features\n",
    "output_file = \"test_data.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Processing /kaggle/input/datavalidation/val/data_1649_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1650_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1637_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1642_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1637_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1637_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1639_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1641_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1642_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1635_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1648_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1648_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1649_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1642_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1640_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1649_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1640_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1646_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1638_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1645_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1641_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1638_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1643_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1639_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1640_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1647_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1638_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1648_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1644_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1646_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1635_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1643_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1638_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1643_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1645_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1646_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1647_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1645_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1650_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1634_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1634_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1634_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1645_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1647_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1647_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1644_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1639_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1634_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1644_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1643_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1641_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1640_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1635_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1646_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1637_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1648_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1636_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1636_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1649_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1642_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1641_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1636_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1650_accel_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1635_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1644_gyro_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1650_gyro_watch.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1639_accel_phone.txt ...\n",
      "Pre-Processing /kaggle/input/datavalidation/val/data_1636_gyro_phone.txt ...\n"
     ]
    }
   ],
   "source": [
    "val_data = preprocess_data(val_datas)\n",
    "# save features\n",
    "output_file = \"val_data.pkl\"\n",
    "with open(output_file, 'wb') as f:\n",
    "    pickle.dump(val_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  test_data.pkl  train_data.pkl  val_data.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
